{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85a33a9f-8498-411d-ae43-5d6120cd1c51",
   "metadata": {},
   "source": [
    "# GNN Recommendation System Example\n",
    "\n",
    "This example is based on the [RecSys Challenge 2015](https://www.kaggle.com/datasets/chadgostopp/recsys-challenge-2015/download?datasetVersionNumber=1). The dataset has been constructed by YOOCHOOSE GmbH, and contains a collection of sessions from a retailer, where each session contains clicks performed by a user in the session. For some sessions there are also buy events, meaning that the session ended with the user buying something from the web shop. Available datasets are as follows:\n",
    "\n",
    "* Clicks dataset\n",
    "  * File `yoochoose-clicks.dat` contains the clicks performed by the users. Data is as follows:\n",
    "    * Session ID - ID of the session\n",
    "    * Timestamp - date and time when the click took place\n",
    "    * Item ID - unique identifier of the item that has been clicked\n",
    "    * Category - context of the click, so that S indicates a special offer, 0 indicates a missing value and any other value represents a brand\n",
    "* Buys dataset\n",
    "  * File `yoochoose-buys.dat` contains the buy events of the users. Data is as follows:\n",
    "    * Sessions ID - ID of the session\n",
    "    * Timestamp - date and time when the buy event took place\n",
    "    * Item ID - unique identifier of the item that has been bought\n",
    "    * Price - price of the item that has been bought\n",
    "    * Quantity - quantity of the items bought\n",
    "* Test dataset\n",
    "  * File `yoochoose-test.dat` contains only clicks of users over time. This is the test file used in the challenge.\n",
    "\n",
    "The idea is to be able to associate click streams with items, so that a user entering the web shop can be recommended items that might be of interest based on the clicks performed by the user. The GNN approach taken in this example is inspired by [Hands-on Graph Neural Networks with PyTorch & PyTorch Geometric](https://towardsdatascience.com/hands-on-graph-neural-networks-with-pytorch-pytorch-geometric-359487e221a8) (code available from [here](https://github.com/khuangaf/PyTorch-Geometric-YooChoose/blob/master/YooChooseClick.ipynb)). The network uses a SageConv layer from [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216) and it is defined as follows:\n",
    "\n",
    "$$\\begin{align}\n",
    "h_{N(v)}^k &\\leftarrow \\text{AGGREGATE}_{k}\\left(\\left\\{h_y^{k-1}, \\forall u \\in N(v)\\right\\}\\right) \\\\\n",
    "h_v^k &\\leftarrow \\sigma \\left(W^k \\cdot \\text{CONCAT}\\left(h_v^{k-1}, h_{N(v)}^k\\right) \\right)\n",
    "\\end{align}$$\n",
    "\n",
    ", where $\\sigma$ is a non-linear activation function. If we use max-pooling as the aggregation method, the right-hand side of the first equation can be written as follows:\n",
    "\n",
    "$$ \\text{AGGREGATE}_{k}\\left(\\left\\{h_y^{k-1}, \\forall u \\in N(v)\\right\\}\\right) = max(\\left(\\left\\{\\sigma \\left(W_\\text{pool}h_{u_i}^k + b \\right), \\forall u_i \\in N(v) \\right\\}\\right))$$\n",
    "\n",
    "Each neighboring node embedding is multiplied by the weight matrix, after which a bias is added, and then an activation-function is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba3e5d6d-ac95-425e-91ad-9c9cb2a5ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.nn import Linear, Parameter, ReLU\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, degree\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv, global_mean_pool, global_max_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "import joblib\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6c7ae5-4ac2-4efa-b552-aba584b209f2",
   "metadata": {},
   "source": [
    "## Data Loader\n",
    "\n",
    "\n",
    "`RecSys2015Dataset` class inherits the base class [InMemoryDataset](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.InMemoryDataset.html), and the functions for downloading and processing input files. Following is a description of the click- and the purchase datasets that are processed into a more appropriate format for the network by the `RecSys2015Dataset`-object.\n",
    "\n",
    "### Click Data\n",
    "\n",
    "Click data consists of the session-id, timestamp, item-id and category of each click stream.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>session_id</th>\n",
    "      <th>timestamp</th>\n",
    "      <th>item_id</th>\n",
    "      <th>category</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>1</td>\n",
    "      <td>2014-04-07T10:54:09.868Z</td>\n",
    "      <td>214536500</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>1</td>\n",
    "      <td>2014-04-07T10:54:46.998Z</td>\n",
    "      <td>214536506</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>1</td>\n",
    "      <td>2014-04-07T10:57:00.306Z</td>\n",
    "      <td>214577561</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>2</td>\n",
    "      <td>2014-04-07T13:56:37.614Z</td>\n",
    "      <td>214662742</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>2</td>\n",
    "      <td>2014-04-07T13:57:19.373Z</td>\n",
    "      <td>214662742</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "### Purchase Data\n",
    "\n",
    "Purchase data consists of the session-id, timestamp, item-id, price and quatity of purchase(s). Purchases can be related to the click-streams using the session-id:s.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>session_id</th>\n",
    "      <th>timestamp</th>\n",
    "      <th>item_id</th>\n",
    "      <th>price</th>\n",
    "      <th>quantity</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>420374</td>\n",
    "      <td>2014-04-06T18:44:58.325Z</td>\n",
    "      <td>214537850</td>\n",
    "      <td>10471</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>281626</td>\n",
    "      <td>2014-04-06T09:40:13.032Z</td>\n",
    "      <td>214535653</td>\n",
    "      <td>1883</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>420368</td>\n",
    "      <td>2014-04-04T06:13:28.848Z</td>\n",
    "      <td>214530572</td>\n",
    "      <td>6073</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>420368</td>\n",
    "      <td>2014-04-04T06:13:28.858Z</td>\n",
    "      <td>214835025</td>\n",
    "      <td>2617</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>140806</td>\n",
    "      <td>2014-04-07T09:22:28.132Z</td>\n",
    "      <td>214668193</td>\n",
    "      <td>523</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "### Converting Click-Stream into a Graph\n",
    "\n",
    "Each of the click-streams, grouped using the session-id:s, represents a graph. Following table shows an example:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>session_id</th>\n",
    "      <th>timestamp</th>\n",
    "      <th>item_id</th>\n",
    "      <th>category</th>\n",
    "      <th>label</th>\n",
    "      <th>node_index</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>743958</th>\n",
    "      <td>239223</td>\n",
    "      <td>2014-04-07T17:18:56.403Z</td>\n",
    "      <td>75</td>\n",
    "      <td>0</td>\n",
    "      <td>False</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>743959</th>\n",
    "      <td>239223</td>\n",
    "      <td>2014-04-07T17:22:01.439Z</td>\n",
    "      <td>85</td>\n",
    "      <td>0</td>\n",
    "      <td>False</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>743960</th>\n",
    "      <td>239223</td>\n",
    "      <td>2014-04-07T17:22:05.276Z</td>\n",
    "      <td>75</td>\n",
    "      <td>0</td>\n",
    "      <td>False</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>743961</th>\n",
    "      <td>239223</td>\n",
    "      <td>2014-04-07T17:22:08.746Z</td>\n",
    "      <td>65</td>\n",
    "      <td>0</td>\n",
    "      <td>False</td>\n",
    "      <td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>743962</th>\n",
    "      <td>239223</td>\n",
    "      <td>2014-04-07T17:22:13.399Z</td>\n",
    "      <td>91</td>\n",
    "      <td>0</td>\n",
    "      <td>False</td>\n",
    "      <td>3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>743963</th>\n",
    "      <td>239223</td>\n",
    "      <td>2014-04-07T17:22:15.920Z</td>\n",
    "      <td>92</td>\n",
    "      <td>0</td>\n",
    "      <td>False</td>\n",
    "      <td>4</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "Node-indices are obtained simply by encoding the item-id:s into unique identifiers using an [OrdinalEncoder](https://scikit-learn.org/0.20/modules/generated/sklearn.preprocessing.OrdinalEncoder.html). In the above example, node connectivity is: \n",
    "\n",
    "$$1 \\rightarrow 2 \\rightarrow 1 \\rightarrow 0 \\rightarrow 3 \\rightarrow 4$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11f225c-9a55-4d82-9fe5-e032fc97345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSys2015Dataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "        # Load parameters\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "        # Load the label-encoder that was created earlier\n",
    "        self.item_id_encoder: OrdinalEncoder = joblib.load(os.path.join(self.processed_dir, \"item_id_encoder.joblib\"))\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [\"yoochoose-buys.dat\",\n",
    "                \"yoochoose-clicks.dat\",\n",
    "                \"yoochoose-test.dat\"]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [\"data.pt\", \"item_id_encoder.joblib\"]\n",
    "\n",
    "    def download(self):\n",
    "        \"\"\"\n",
    "        Downloads the data, unless it exists already.\n",
    "        \"\"\"\n",
    "        # Download data and move to self.raw_dir\n",
    "        od.download(\"https://www.kaggle.com/datasets/chadgostopp/recsys-challenge-2015/download?datasetVersionNumber=1\")\n",
    "        os.rename('recsys-challenge-2015', self.raw_dir)\n",
    "        os.removedirs('recsys-challenge-2015')\n",
    "\n",
    "    def get_max_item_id(self):\n",
    "        \"\"\"\n",
    "        Get maximum item id\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Maximum item id\n",
    "        \"\"\"\n",
    "        return self._data.x.max().item()\n",
    "\n",
    "    def encode_item_ids(self, x):\n",
    "        \"\"\"\n",
    "        Encode item IDs\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array-like of shape (n_samples, n_features)\n",
    "            Item IDs to be encoded\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Encoded item IDs\n",
    "        \"\"\"\n",
    "        return self.item_id_encoder.transform(x)\n",
    "\n",
    "    def decode_item_ids(self, x):\n",
    "        \"\"\"\n",
    "        Decode encoded item IDs\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array-like of shape (n_samples, n_features)\n",
    "            Encoded item IDs\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.ndarray\n",
    "            Decode item IDs\n",
    "        \"\"\"\n",
    "        return self.item_id_encoder.inverse_transform(x)\n",
    "\n",
    "    def process(self):\n",
    "        \"\"\"\n",
    "        Processes in input files and converts these into node features, connectivity information for the\n",
    "        edges and target information.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        FileNotFoundError\n",
    "            Raised if the file yoochoose-buys.dat is not found\n",
    "        FileNotFoundError\n",
    "            Raise if the file yoochoose-clicks.dat is not found\n",
    "        \"\"\"\n",
    "        # Read the csv files\n",
    "        buy_data_path = os.path.join(self.raw_dir, 'yoochoose-buys.dat')\n",
    "        click_data_path = os.path.join(self.raw_dir, 'yoochoose-clicks.dat')\n",
    "\n",
    "        # Verify that the files exist\n",
    "        if not os.path.isfile(buy_data_path):\n",
    "            raise FileNotFoundError(buy_data_path)\n",
    "\n",
    "        if not os.path.isfile(click_data_path):\n",
    "            raise FileNotFoundError(click_data_path)\n",
    "\n",
    "        # Read in the data files\n",
    "        purchases = pd.read_csv(buy_data_path, dtype={2: 'int'})\n",
    "        purchases.columns = [\"session_id\", \"timestamp\", \"item_id\", \"price\", \"quantity\"]\n",
    "        \n",
    "        clicks = pd.read_csv(click_data_path, dtype={2: 'int', 3: 'str'})\n",
    "        clicks.columns = [\"session_id\", \"timestamp\", \"item_id\", \"category\"]\n",
    "\n",
    "        # Print contents of purchases and clicks\n",
    "        # clicks_small = clicks.head(5)\n",
    "        # clicks_small.to_html('clicks.html')\n",
    "        # clicks_small.to_markdown('clicks.md')\n",
    "        # purchases_small = purchases.head(5)\n",
    "        # purchases_small.to_html('purchases.html')\n",
    "        # purchases_small.to_markdown('purchases.md')\n",
    "\n",
    "        # Choose 1M random (unique) clicks from the data\n",
    "        sampled_session_id = np.random.choice(clicks.session_id.unique(), 1000000, replace=False)\n",
    "        clicks = clicks.loc[clicks.session_id.isin(sampled_session_id)]\n",
    "\n",
    "        # Encode the item_id:s\n",
    "        item_id_encoder = OrdinalEncoder()\n",
    "        item_id_encoder.fit(clicks.item_id.to_numpy().reshape(-1, 1))\n",
    "        clicks.item_id = item_id_encoder.transform(clicks.item_id.to_numpy().reshape(-1, 1))\n",
    "\n",
    "        # Encode the categories\n",
    "        category_encoder = OrdinalEncoder()\n",
    "        category_encoder.fit(clicks.category.to_numpy().reshape(-1, 1))\n",
    "        clicks.category = category_encoder.transform(clicks.category.to_numpy().reshape(-1, 1))\n",
    "        \n",
    "        # Filter out those click-sessions that have less than 2 clicks\n",
    "        clicks = clicks[clicks['session_id'].map(clicks['session_id'].value_counts() > 2)]\n",
    "\n",
    "        # Did the clicking session lead to a purchase event?\n",
    "        clicks['label'] = clicks.session_id.isin(purchases['session_id'])\n",
    "\n",
    "        data_list = []\n",
    "\n",
    "        # Iterate over groups of session IDs\n",
    "        for session_id, group in tqdm(clicks.groupby('session_id')):\n",
    "            \n",
    "            # Encode item_id of each group. Encoded item_id is the node_index\n",
    "            encoder = LabelEncoder()\n",
    "            group['node_index'] = encoder.fit_transform(group['item_id'])\n",
    "            \n",
    "            # Node features -> [node_index, item_id]\n",
    "            #node_features = group.loc[group.session_id == session_id, ['node_index', 'item_id']].sort_values('node_index')\n",
    "            node_features = group[['node_index', 'item_id', 'category']].reset_index(drop=True)\n",
    "\n",
    "            # Target- and source nodes\n",
    "            target_nodes = group.node_index[1:].reset_index(drop=True)\n",
    "            source_nodes = group.node_index[:-1].reset_index(drop=True)\n",
    "\n",
    "            # Edge indices [source -> target]\n",
    "            edge_index = torch.tensor(np.vstack((source_nodes.to_numpy(), target_nodes.to_numpy())), dtype=torch.long)\n",
    "\n",
    "            # 'x' consists of the node features [node_index, item_id, category]\n",
    "            x = torch.IntTensor(node_features.to_numpy())\n",
    "            # 'y' marks if there was a buying decision (True/False) at the end of the clicking session\n",
    "            y = torch.FloatTensor([int(group.label.iloc[0])])\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "        joblib.dump(item_id_encoder, os.path.join(self.processed_dir, \"item_id_encoder.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2565b80a-2b94-4b96-b6d0-0caff20d7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGEConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    Implementation of the GraphSAGE operator from https://arxiv.org/abs/1706.02216\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        SAGEConv constructor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_channels : int\n",
    "            Size of input\n",
    "        out_channels : int\n",
    "            Size of output\n",
    "        \"\"\"\n",
    "        super(SAGEConv, self).__init__(aggr='max')\n",
    "\n",
    "        self.linear_aggregate = Linear(in_channels, out_channels)\n",
    "        self.activation_aggregate = ReLU()\n",
    "        self.update_linear = Linear(in_channels + out_channels, in_channels, bias=False)\n",
    "        self.update_activation = ReLU()\n",
    "\n",
    "    def forward(self, x: torch.tensor, edge_index: torch.tensor):\n",
    "        \"\"\"\n",
    "        Runs the forward pass of the module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.tensor\n",
    "            embeddings\n",
    "        edge_index : torch.tensor\n",
    "            edge indices\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        _type_\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        edge_index, _ = remove_self_loops(edge_index)\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "\n",
    "    def update(self, aggr_out, x):\n",
    "        \"\"\"\n",
    "        Updates node embeddings. Takes in the output of aggregation as first argument and any argument\n",
    "        which was initially passed to propagate(). Concatenates the aggregated message and the current\n",
    "        node's embeddings, and then applies linear- and activation functions on the concatenated tensors.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        aggr_out : torch.tensor\n",
    "            Aggregated message\n",
    "        x : torch.tensor\n",
    "            Current node's embedding\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            Updated node embedding\n",
    "        \"\"\"\n",
    "\n",
    "        new_embedding = torch.cat([aggr_out, x], dim=1)\n",
    "        new_embedding = self.update_linear(new_embedding)\n",
    "        new_embedding = self.update_activation(new_embedding)\n",
    "\n",
    "        return new_embedding\n",
    "    \n",
    "    def message(self, x_j):\n",
    "        \"\"\"\n",
    "        Constructs messages from node j to node i for each edge in edge_index. Applies linear- and\n",
    "        activation functions for each neighboring node's embeddings.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x_j : torch.tensor\n",
    "            _description_\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            Constructed message\n",
    "        \"\"\"\n",
    "\n",
    "        x_j = self.linear_aggregate(x_j)\n",
    "        x_j = self.activation_aggregate(x_j)\n",
    "\n",
    "        return x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a68fc8c-58a9-42ad-9561-dd9f1af3add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dimension = 16, dropout_probability = 0.5):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.dropout_probability = dropout_probability\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2*self.embedding_dimension, self.embedding_dimension),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(p=self.dropout_probability),\n",
    "            torch.nn.Linear(self.embedding_dimension, 8),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(p=self.dropout_probability),\n",
    "            torch.nn.Linear(8, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.conv1 = SAGEConv(in_channels=self.embedding_dimension, out_channels=self.embedding_dimension)\n",
    "        self.pool1 = TopKPooling(in_channels=self.embedding_dimension, ratio=0.8)\n",
    "        self.conv2 = SAGEConv(in_channels=self.embedding_dimension, out_channels=self.embedding_dimension)\n",
    "        self.pool2 = TopKPooling(self.embedding_dimension, ratio=0.8)\n",
    "        self.conv3 = SAGEConv(in_channels=self.embedding_dimension, out_channels=self.embedding_dimension)\n",
    "        self.pool3 = TopKPooling(self.embedding_dimension, ratio=0.8)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=self.num_embeddings, embedding_dim=self.embedding_dimension)\n",
    "        self.dropout = torch.nn.Dropout(p=self.dropout_probability)\n",
    "\n",
    "    def forward(self, data: torch_geometric.data.batch):\n",
    "        \"\"\"\n",
    "        Inference\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : torch_geometric.data.batch\n",
    "                x: torch.tensor\n",
    "                    [node_index, item_id, category]\n",
    "                edge_index: torch.tensor\n",
    "                    Node connectivity\n",
    "                batch: torch.tensor\n",
    "                    Batch information\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.tensor\n",
    "            Probability of a buying decision [0...1]\n",
    "        \"\"\"\n",
    "\n",
    "        x, edge_index, batch = data.x[:, 1], data.edge_index, data.batch\n",
    "\n",
    "        # Calculate embeddings\n",
    "        x = self.item_embedding(x)\n",
    "        x = x.squeeze(1)\n",
    "\n",
    "        # 1st message passing round\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x, edge_index, _, batch, *rest = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        # 2nd message passing round\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x, edge_index, _, batch, *rest = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        # 3rd message passing round\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x, edge_index, _, batch, *rest = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "        \n",
    "        x = self.mlp(x)\n",
    "\n",
    "        return torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb9547a-0923-429a-9dbb-d669fc9767a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.get(0)=Data(x=[10, 3], edge_index=[2, 9], y=[1])\n",
      "dataset.get(1)=Data(x=[3, 3], edge_index=[2, 2], y=[1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarno/miniconda3/envs/pytorch-pyg-gpu/lib/python3.10/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator OrdinalEncoder from version 1.3.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create / load the dataset\n",
    "dataset = RecSys2015Dataset('RecSys2015_data')\n",
    "\n",
    "# Print data from the dataset\n",
    "print(f\"{dataset.get(0)=}\")\n",
    "print(f\"{dataset.get(1)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fbb6483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training- and validation datasets\n",
    "indices = torch.randperm(len(dataset))\n",
    "train_size = int(0.8*len(dataset))\n",
    "train_indices = indices[:train_size]\n",
    "validation_indices = indices[train_size:]\n",
    "\n",
    "training_dataset = dataset[train_indices]\n",
    "validation_dataset = dataset[validation_indices]\n",
    "\n",
    "# Create training- and validation data \n",
    "batch_size = 32\n",
    "training_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, num_workers=0)\n",
    "total_epochs_per_epoch = math.ceil(len(training_dataset) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a3ff9e-cfe2-452a-9f08-5e09e9656456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Number of embeddings: 35661\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "max_item_id = dataset.get_max_item_id()\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Number of embeddings: {max_item_id}\")\n",
    "\n",
    "model = GNN(num_embeddings = max_item_id+1, dropout_probability=0.5).to(device)\n",
    "# For criteria we use binary cross entropy loss -> buy / no buy\n",
    "criteria = torch.nn.BCELoss()\n",
    "# AdamW optimizer -> original Adam contains a mathematical error in the weights calculation\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9910e0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 478925\n",
      "Samples in the training dataloader: 11974\n",
      "Samples in the validation dataloader: 2994\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"Samples in the training dataloader: {len(training_loader)}\")\n",
    "print(f\"Samples in the validation dataloader: {len(validation_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b58f7a-045b-47a8-84c0-9ac04b43b027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], step [1/11974], training loss: 0.6182\n",
      "Epoch [1/10], step [1001/11974], training loss: 0.3498\n",
      "Epoch [1/10], step [2001/11974], training loss: 0.2901\n",
      "Epoch [1/10], step [3001/11974], training loss: 0.3965\n",
      "Epoch [1/10], step [4001/11974], training loss: 0.1424\n",
      "Epoch [1/10], step [5001/11974], training loss: 0.4774\n",
      "Epoch [1/10], step [6001/11974], training loss: 0.2735\n",
      "Epoch [1/10], step [7001/11974], training loss: 0.3502\n",
      "Epoch [1/10], step [8001/11974], training loss: 0.3518\n",
      "Epoch [1/10], step [9001/11974], training loss: 0.3975\n",
      "Epoch [1/10], step [10001/11974], training loss: 0.2031\n",
      "Epoch [1/10], step [11001/11974], training loss: 0.2083\n",
      "Epoch [1/10], training accuracy: 0.9150, training loss: 0.2940\n",
      "Epoch [1/10], validation accuracy: 0.9143, validation loss: 0.2831\n",
      "Saved the model, lowest validation loss: 0.2831\n",
      "----------------------------\n",
      "Epoch [2/10], step [1/11974], training loss: 0.2033\n",
      "Epoch [2/10], step [1001/11974], training loss: 0.4983\n",
      "Epoch [2/10], step [2001/11974], training loss: 0.2417\n",
      "Epoch [2/10], step [3001/11974], training loss: 0.3638\n",
      "Epoch [2/10], step [4001/11974], training loss: 0.2646\n",
      "Epoch [2/10], step [5001/11974], training loss: 0.2655\n",
      "Epoch [2/10], step [6001/11974], training loss: 0.2547\n",
      "Epoch [2/10], step [7001/11974], training loss: 0.2598\n",
      "Epoch [2/10], step [8001/11974], training loss: 0.2288\n",
      "Epoch [2/10], step [9001/11974], training loss: 0.3419\n",
      "Epoch [2/10], step [10001/11974], training loss: 0.4548\n",
      "Epoch [2/10], step [11001/11974], training loss: 0.3019\n",
      "Epoch [2/10], training accuracy: 0.9150, training loss: 0.2759\n",
      "Epoch [2/10], validation accuracy: 0.9143, validation loss: 0.2771\n",
      "Saved the model, lowest validation loss: 0.2771\n",
      "----------------------------\n",
      "Epoch [3/10], step [1/11974], training loss: 0.3418\n",
      "Epoch [3/10], step [1001/11974], training loss: 0.2581\n",
      "Epoch [3/10], step [2001/11974], training loss: 0.2691\n",
      "Epoch [3/10], step [3001/11974], training loss: 0.2559\n",
      "Epoch [3/10], step [4001/11974], training loss: 0.2479\n",
      "Epoch [3/10], step [5001/11974], training loss: 0.2152\n",
      "Epoch [3/10], step [6001/11974], training loss: 0.2231\n",
      "Epoch [3/10], step [7001/11974], training loss: 0.2633\n",
      "Epoch [3/10], step [8001/11974], training loss: 0.3298\n",
      "Epoch [3/10], step [9001/11974], training loss: 0.2587\n",
      "Epoch [3/10], step [10001/11974], training loss: 0.2950\n",
      "Epoch [3/10], step [11001/11974], training loss: 0.2034\n",
      "Epoch [3/10], training accuracy: 0.9150, training loss: 0.2708\n",
      "Epoch [3/10], validation accuracy: 0.9143, validation loss: 0.2744\n",
      "Saved the model, lowest validation loss: 0.2744\n",
      "----------------------------\n",
      "Epoch [4/10], step [1/11974], training loss: 0.4033\n",
      "Epoch [4/10], step [1001/11974], training loss: 0.2056\n",
      "Epoch [4/10], step [2001/11974], training loss: 0.2713\n",
      "Epoch [4/10], step [3001/11974], training loss: 0.2294\n",
      "Epoch [4/10], step [4001/11974], training loss: 0.2209\n",
      "Epoch [4/10], step [5001/11974], training loss: 0.2099\n",
      "Epoch [4/10], step [6001/11974], training loss: 0.0936\n",
      "Epoch [4/10], step [7001/11974], training loss: 0.2692\n",
      "Epoch [4/10], step [8001/11974], training loss: 0.1738\n",
      "Epoch [4/10], step [9001/11974], training loss: 0.1873\n",
      "Epoch [4/10], step [10001/11974], training loss: 0.2384\n",
      "Epoch [4/10], step [11001/11974], training loss: 0.2727\n",
      "Epoch [4/10], training accuracy: 0.9148, training loss: 0.2667\n",
      "Epoch [4/10], validation accuracy: 0.9143, validation loss: 0.2748\n",
      "----------------------------\n",
      "Epoch [5/10], step [1/11974], training loss: 0.4928\n",
      "Epoch [5/10], step [1001/11974], training loss: 0.2800\n",
      "Epoch [5/10], step [2001/11974], training loss: 0.2527\n",
      "Epoch [5/10], step [3001/11974], training loss: 0.2658\n",
      "Epoch [5/10], step [4001/11974], training loss: 0.2417\n",
      "Epoch [5/10], step [5001/11974], training loss: 0.1680\n",
      "Epoch [5/10], step [6001/11974], training loss: 0.2817\n",
      "Epoch [5/10], step [7001/11974], training loss: 0.1712\n",
      "Epoch [5/10], step [8001/11974], training loss: 0.5089\n",
      "Epoch [5/10], step [9001/11974], training loss: 0.1280\n",
      "Epoch [5/10], step [10001/11974], training loss: 0.1438\n",
      "Epoch [5/10], step [11001/11974], training loss: 0.1427\n",
      "Epoch [5/10], training accuracy: 0.9148, training loss: 0.2642\n",
      "Epoch [5/10], validation accuracy: 0.9143, validation loss: 0.2750\n",
      "----------------------------\n",
      "Epoch [6/10], step [1/11974], training loss: 0.4138\n",
      "Epoch [6/10], step [1001/11974], training loss: 0.2551\n",
      "Epoch [6/10], step [2001/11974], training loss: 0.1645\n",
      "Epoch [6/10], step [3001/11974], training loss: 0.2841\n",
      "Epoch [6/10], step [4001/11974], training loss: 0.1956\n",
      "Epoch [6/10], step [5001/11974], training loss: 0.1818\n",
      "Epoch [6/10], step [6001/11974], training loss: 0.3218\n",
      "Epoch [6/10], step [7001/11974], training loss: 0.1969\n",
      "Epoch [6/10], step [8001/11974], training loss: 0.3111\n",
      "Epoch [6/10], step [9001/11974], training loss: 0.0899\n",
      "Epoch [6/10], step [10001/11974], training loss: 0.2476\n",
      "Epoch [6/10], step [11001/11974], training loss: 0.1421\n",
      "Epoch [6/10], training accuracy: 0.9146, training loss: 0.2620\n",
      "Epoch [6/10], validation accuracy: 0.9143, validation loss: 0.2737\n",
      "Saved the model, lowest validation loss: 0.2737\n",
      "----------------------------\n",
      "Epoch [7/10], step [1/11974], training loss: 0.3469\n",
      "Epoch [7/10], step [1001/11974], training loss: 0.2642\n",
      "Epoch [7/10], step [2001/11974], training loss: 0.1005\n",
      "Epoch [7/10], step [3001/11974], training loss: 0.2590\n",
      "Epoch [7/10], step [4001/11974], training loss: 0.3313\n",
      "Epoch [7/10], step [5001/11974], training loss: 0.3104\n",
      "Epoch [7/10], step [6001/11974], training loss: 0.2620\n",
      "Epoch [7/10], step [7001/11974], training loss: 0.2719\n",
      "Epoch [7/10], step [8001/11974], training loss: 0.1986\n",
      "Epoch [7/10], step [9001/11974], training loss: 0.1738\n",
      "Epoch [7/10], step [10001/11974], training loss: 0.2193\n",
      "Epoch [7/10], step [11001/11974], training loss: 0.2777\n",
      "Epoch [7/10], training accuracy: 0.9148, training loss: 0.2608\n",
      "Epoch [7/10], validation accuracy: 0.9143, validation loss: 0.2755\n",
      "----------------------------\n",
      "Epoch [8/10], step [1/11974], training loss: 0.4556\n",
      "Epoch [8/10], step [1001/11974], training loss: 0.2260\n",
      "Epoch [8/10], step [2001/11974], training loss: 0.1986\n",
      "Epoch [8/10], step [3001/11974], training loss: 0.1580\n",
      "Epoch [8/10], step [4001/11974], training loss: 0.1653\n",
      "Epoch [8/10], step [5001/11974], training loss: 0.1831\n",
      "Epoch [8/10], step [6001/11974], training loss: 0.3393\n",
      "Epoch [8/10], step [7001/11974], training loss: 0.1709\n",
      "Epoch [8/10], step [8001/11974], training loss: 0.1824\n",
      "Epoch [8/10], step [9001/11974], training loss: 0.2466\n",
      "Epoch [8/10], step [10001/11974], training loss: 0.2064\n",
      "Epoch [8/10], step [11001/11974], training loss: 0.1737\n",
      "Epoch [8/10], training accuracy: 0.9146, training loss: 0.2597\n",
      "Epoch [8/10], validation accuracy: 0.9143, validation loss: 0.2727\n",
      "Saved the model, lowest validation loss: 0.2727\n",
      "----------------------------\n",
      "Epoch [9/10], step [1/11974], training loss: 0.2009\n",
      "Epoch [9/10], step [1001/11974], training loss: 0.0819\n",
      "Epoch [9/10], step [2001/11974], training loss: 0.1639\n",
      "Epoch [9/10], step [3001/11974], training loss: 0.1958\n",
      "Epoch [9/10], step [4001/11974], training loss: 0.2627\n",
      "Epoch [9/10], step [5001/11974], training loss: 0.1825\n",
      "Epoch [9/10], step [6001/11974], training loss: 0.3246\n",
      "Epoch [9/10], step [7001/11974], training loss: 0.2136\n",
      "Epoch [9/10], step [8001/11974], training loss: 0.2110\n",
      "Epoch [9/10], step [9001/11974], training loss: 0.1531\n",
      "Epoch [9/10], step [10001/11974], training loss: 0.2620\n",
      "Epoch [9/10], step [11001/11974], training loss: 0.4956\n",
      "Epoch [9/10], training accuracy: 0.9148, training loss: 0.2587\n",
      "Epoch [9/10], validation accuracy: 0.9143, validation loss: 0.2740\n",
      "----------------------------\n",
      "Epoch [10/10], step [1/11974], training loss: 0.1743\n",
      "Epoch [10/10], step [1001/11974], training loss: 0.3483\n",
      "Epoch [10/10], step [2001/11974], training loss: 0.2693\n",
      "Epoch [10/10], step [3001/11974], training loss: 0.1753\n",
      "Epoch [10/10], step [4001/11974], training loss: 0.1295\n",
      "Epoch [10/10], step [5001/11974], training loss: 0.1536\n",
      "Epoch [10/10], step [6001/11974], training loss: 0.0910\n",
      "Epoch [10/10], step [7001/11974], training loss: 0.1051\n",
      "Epoch [10/10], step [8001/11974], training loss: 0.2655\n",
      "Epoch [10/10], step [9001/11974], training loss: 0.6952\n",
      "Epoch [10/10], step [10001/11974], training loss: 0.1619\n",
      "Epoch [10/10], step [11001/11974], training loss: 0.4181\n",
      "Epoch [10/10], training accuracy: 0.9149, training loss: 0.2584\n",
      "Epoch [10/10], validation accuracy: 0.9143, validation loss: 0.2739\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "lowest_loss = math.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_training_loss = 0\n",
    "    epoch_training_total_correct = 0\n",
    "    epoch_training_total_samples = 0\n",
    "    epoch_validation_loss = 0\n",
    "    epoch_validation_total_correct = 0\n",
    "    epoch_validation_total_samples = 0\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    for index, data in enumerate(training_loader):\n",
    "\n",
    "        # Send data to device\n",
    "        data = data.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        prediction = model(data)\n",
    "\n",
    "        # Loss and accuracy\n",
    "        loss = criteria(prediction, data.y)\n",
    "        epoch_training_loss += loss.item()\n",
    "        epoch_training_total_samples += len(data)\n",
    "        predicted_class = torch.round(prediction)\n",
    "        epoch_training_total_correct += (data.y == predicted_class).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (index) % 1000 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], step [{index+1}/{total_epochs_per_epoch}], training loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    for data in validation_loader:\n",
    "\n",
    "        # Send data to device\n",
    "        data = data.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        prediction = model(data)\n",
    "\n",
    "        # Loass and accuracy\n",
    "        loss = criteria(prediction, data.y)\n",
    "        epoch_validation_loss += loss.item()\n",
    "        epoch_validation_total_samples += len(data)\n",
    "        predicted_class = torch.round(prediction)\n",
    "        epoch_validation_total_correct += (data.y == predicted_class).sum().item()\n",
    "\n",
    "    epoch_training_loss /= len(training_loader)\n",
    "    epoch_validation_loss /= len(validation_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], training accuracy: {(epoch_training_total_correct/epoch_training_total_samples):.4f}, training loss: {epoch_training_loss:.4f}\")\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], validation accuracy: {(epoch_validation_total_correct/epoch_validation_total_samples):.4f}, validation loss: {epoch_validation_loss:.4f}\")\n",
    "\n",
    "    # Save model is validation loss is lower than before\n",
    "    if epoch_validation_loss < lowest_loss:\n",
    "        torch.save(model.state_dict(), 'GNN_recommendation_systemrecsys_2015.pth')\n",
    "        lowest_loss = epoch_validation_loss\n",
    "        print(f\"Saved the model, lowest validation loss: {lowest_loss:.4f}\")\n",
    "    print(\"----------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
