{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2d777e",
   "metadata": {},
   "source": [
    "# Simple Linear Regression Example\n",
    "\n",
    "This example uses the diabetes data from Sklearn in order to train a linear regression model. The data contains ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "Attribute information: \n",
    "- ***age*** age in years\n",
    "- ***sex*** sex of the person in question\n",
    "- ***bmi*** body mass index\n",
    "- ***bp*** average blood pressure\n",
    "- ***s1*** tc, total serum cholesterol\n",
    "- ***s2*** ldl, low-density lipoproteins\n",
    "- ***s3*** hdl, high-density lipoproteins\n",
    "- ***s4*** tch, total cholesterol / HDL\n",
    "- ***s5*** ltg, possibly log of serum triglycerides level\n",
    "- ***s6*** glu, blood sugar level\n",
    "\n",
    "The model (linear algebra) is $Ax = y$, where length of $x$ is 10+1 due to the bias term. In deep learning terms this can be interpreted as $y=w^tx + b$, where $x$ is the feature vector (i.e. the attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "210ec8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Reduce TF verbosity\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('INFO') # Reduce TF verbosity\n",
    "print(f\"tensorflow version: {tf.__version__}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b812258",
   "metadata": {},
   "source": [
    "## Load data and display feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979662d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data: <class 'sklearn.utils.Bunch'>\n",
      "Keys: dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])\n",
      "Feature names: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "Size of data.data: (442, 10)\n",
      "Size of data.target: (442,)\n"
     ]
    }
   ],
   "source": [
    "data = load_diabetes()\n",
    "\n",
    "print(f\"Type of data: {type(data)}\")\n",
    "print(f\"Keys: {data.keys()}\")\n",
    "print(f\"Feature names: {data.feature_names}\")\n",
    "print(f\"Size of data.data: {data.data.shape}\")\n",
    "print(f\"Size of data.target: {data.target.shape}\")\n",
    "N, D = data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae8b12d",
   "metadata": {},
   "source": [
    "## Normalize the data, and split it into training- and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b8c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "# Normalize X\n",
    "X -= X.mean()\n",
    "y = data.target\n",
    "\n",
    "# Sprint input features and target into train- and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982aa9e",
   "metadata": {},
   "source": [
    "## Create the model, and display summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0147f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(D,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc37aaa",
   "metadata": {},
   "source": [
    "## Compile the model, and train it. After 50 epochs, learning rate is reduced using a callback-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ae8519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 1s 15ms/step - loss: 20949.9531 - val_loss: 8189.3862 - lr: 0.0100\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 6499.8691 - val_loss: 8685.0918 - lr: 0.0100\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 7543.3828 - val_loss: 7572.8931 - lr: 0.0100\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5723.6265 - val_loss: 6293.8740 - lr: 0.0100\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5578.2803 - val_loss: 6228.6709 - lr: 0.0100\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5374.6895 - val_loss: 6199.2954 - lr: 0.0100\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5254.7964 - val_loss: 6121.3247 - lr: 0.0100\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5173.9868 - val_loss: 6026.0264 - lr: 0.0100\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5118.3657 - val_loss: 5966.0317 - lr: 0.0100\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 5088.2563 - val_loss: 5964.0864 - lr: 0.0100\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4986.4941 - val_loss: 5845.6479 - lr: 0.0100\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4923.7085 - val_loss: 5770.8579 - lr: 0.0100\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4873.1001 - val_loss: 5716.1440 - lr: 0.0100\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4814.6641 - val_loss: 5679.5249 - lr: 0.0100\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4761.8062 - val_loss: 5638.6577 - lr: 0.0100\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4716.1851 - val_loss: 5571.7417 - lr: 0.0100\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4663.3022 - val_loss: 5553.3027 - lr: 0.0100\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4618.1079 - val_loss: 5492.6108 - lr: 0.0100\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4568.2422 - val_loss: 5427.4014 - lr: 0.0100\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4514.7271 - val_loss: 5400.2310 - lr: 0.0100\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4479.2036 - val_loss: 5379.6226 - lr: 0.0100\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4439.3608 - val_loss: 5379.4897 - lr: 0.0100\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4397.6523 - val_loss: 5272.3281 - lr: 0.0100\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4346.7524 - val_loss: 5230.4634 - lr: 0.0100\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4309.9897 - val_loss: 5197.6138 - lr: 0.0100\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4272.9263 - val_loss: 5157.0469 - lr: 0.0100\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4240.5542 - val_loss: 5132.8447 - lr: 0.0100\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4207.3433 - val_loss: 5113.1235 - lr: 0.0100\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4173.6865 - val_loss: 5075.7490 - lr: 0.0100\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4145.8984 - val_loss: 5033.5469 - lr: 0.0100\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4111.4795 - val_loss: 5020.7354 - lr: 0.0100\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4081.2817 - val_loss: 5004.6543 - lr: 0.0100\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 4047.8899 - val_loss: 4962.8257 - lr: 0.0100\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4018.7322 - val_loss: 4919.7393 - lr: 0.0100\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3995.9114 - val_loss: 4895.9731 - lr: 0.0100\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3968.9866 - val_loss: 4869.9014 - lr: 0.0100\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3929.0469 - val_loss: 4903.5688 - lr: 0.0100\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3919.4160 - val_loss: 4842.7217 - lr: 0.0100\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3893.9041 - val_loss: 4797.9937 - lr: 0.0100\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3853.3149 - val_loss: 4802.7036 - lr: 0.0100\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3853.4670 - val_loss: 4820.8198 - lr: 0.0100\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3817.4827 - val_loss: 4726.1807 - lr: 0.0100\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3794.7478 - val_loss: 4699.7544 - lr: 0.0100\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3776.7024 - val_loss: 4726.4282 - lr: 0.0100\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3751.5237 - val_loss: 4708.5869 - lr: 0.0100\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3722.8687 - val_loss: 4641.2891 - lr: 0.0100\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3700.4912 - val_loss: 4633.8491 - lr: 0.0100\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3675.2263 - val_loss: 4633.6865 - lr: 0.0100\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3671.6882 - val_loss: 4654.5190 - lr: 0.0100\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3651.5811 - val_loss: 4596.3105 - lr: 0.0100\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3624.7854 - val_loss: 4582.7466 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3617.7314 - val_loss: 4579.3564 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3613.3179 - val_loss: 4574.6079 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3611.2795 - val_loss: 4572.1724 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3609.2100 - val_loss: 4568.1533 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3606.8853 - val_loss: 4565.6021 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3605.1604 - val_loss: 4563.7646 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3603.1833 - val_loss: 4561.7310 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3601.4084 - val_loss: 4561.4297 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3599.5364 - val_loss: 4562.4419 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3598.1665 - val_loss: 4559.6821 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3596.2200 - val_loss: 4557.9487 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3594.7957 - val_loss: 4554.6841 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3593.1812 - val_loss: 4554.5513 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3591.3071 - val_loss: 4550.4761 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3590.1440 - val_loss: 4546.7778 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3586.9663 - val_loss: 4542.2065 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3589.1313 - val_loss: 4537.4614 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3585.6714 - val_loss: 4538.3926 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3583.9397 - val_loss: 4540.9219 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3581.7759 - val_loss: 4537.7339 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3579.6384 - val_loss: 4536.4941 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3578.5793 - val_loss: 4536.8257 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3576.6584 - val_loss: 4535.4023 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3575.1169 - val_loss: 4533.6958 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3576.0706 - val_loss: 4536.5659 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3571.8813 - val_loss: 4532.2129 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3569.6006 - val_loss: 4532.7759 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3568.0950 - val_loss: 4530.3438 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3566.3472 - val_loss: 4527.3818 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3564.1621 - val_loss: 4523.6909 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3563.1292 - val_loss: 4518.4819 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3563.4114 - val_loss: 4514.9263 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3561.0642 - val_loss: 4514.6377 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3559.1313 - val_loss: 4512.1880 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3557.5007 - val_loss: 4511.6396 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3555.4648 - val_loss: 4512.3857 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3556.0515 - val_loss: 4516.5830 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3550.8711 - val_loss: 4518.7334 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3550.0000 - val_loss: 4518.5186 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3549.4741 - val_loss: 4519.5635 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3547.3555 - val_loss: 4516.0054 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3545.2129 - val_loss: 4511.8906 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3544.7507 - val_loss: 4506.3589 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3542.2217 - val_loss: 4505.6152 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3540.7432 - val_loss: 4502.0259 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3539.1255 - val_loss: 4501.8887 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3537.3770 - val_loss: 4500.0259 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3536.5876 - val_loss: 4498.7241 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3533.9919 - val_loss: 4495.5347 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3533.0686 - val_loss: 4491.7378 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3532.8179 - val_loss: 4492.4629 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3529.8240 - val_loss: 4491.6094 - lr: 0.0010\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3528.3628 - val_loss: 4490.3740 - lr: 0.0010\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3525.9844 - val_loss: 4491.8760 - lr: 0.0010\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3524.9639 - val_loss: 4493.7334 - lr: 0.0010\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3526.8960 - val_loss: 4497.5269 - lr: 0.0010\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3522.6260 - val_loss: 4495.8320 - lr: 0.0010\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3520.4023 - val_loss: 4490.2202 - lr: 0.0010\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3518.6467 - val_loss: 4486.2275 - lr: 0.0010\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3517.2107 - val_loss: 4484.2866 - lr: 0.0010\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3515.5132 - val_loss: 4483.3384 - lr: 0.0010\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3514.3826 - val_loss: 4479.5942 - lr: 0.0010\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3516.0149 - val_loss: 4475.1523 - lr: 0.0010\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3513.2039 - val_loss: 4477.8330 - lr: 0.0010\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3511.3608 - val_loss: 4478.3828 - lr: 0.0010\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3508.3540 - val_loss: 4473.1831 - lr: 0.0010\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3507.3513 - val_loss: 4474.3350 - lr: 0.0010\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3505.2803 - val_loss: 4474.2969 - lr: 0.0010\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3504.0256 - val_loss: 4474.5474 - lr: 0.0010\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3502.6687 - val_loss: 4473.2368 - lr: 0.0010\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3501.0229 - val_loss: 4468.5508 - lr: 0.0010\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3500.0117 - val_loss: 4464.2153 - lr: 0.0010\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3498.2214 - val_loss: 4464.6865 - lr: 0.0010\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3496.1697 - val_loss: 4466.9116 - lr: 0.0010\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3494.1309 - val_loss: 4468.7651 - lr: 0.0010\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3494.9294 - val_loss: 4471.6548 - lr: 0.0010\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3492.9290 - val_loss: 4470.0742 - lr: 0.0010\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3490.8855 - val_loss: 4465.3682 - lr: 0.0010\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3490.5029 - val_loss: 4468.5308 - lr: 0.0010\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3489.3462 - val_loss: 4468.2246 - lr: 0.0010\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3487.6819 - val_loss: 4466.3872 - lr: 0.0010\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3484.5918 - val_loss: 4460.7007 - lr: 0.0010\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3483.9495 - val_loss: 4457.3809 - lr: 0.0010\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3481.6030 - val_loss: 4456.1968 - lr: 0.0010\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3480.3572 - val_loss: 4454.7607 - lr: 0.0010\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3479.7463 - val_loss: 4457.0908 - lr: 0.0010\n",
      "Epoch 138/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 6ms/step - loss: 3477.1968 - val_loss: 4452.1997 - lr: 0.0010\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3477.6414 - val_loss: 4446.7939 - lr: 0.0010\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3474.3069 - val_loss: 4445.6279 - lr: 0.0010\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3473.1167 - val_loss: 4442.0259 - lr: 0.0010\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3471.3867 - val_loss: 4442.7993 - lr: 0.0010\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3470.8118 - val_loss: 4443.6841 - lr: 0.0010\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3468.9041 - val_loss: 4439.4688 - lr: 0.0010\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3467.1011 - val_loss: 4438.9575 - lr: 0.0010\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3466.4937 - val_loss: 4437.2935 - lr: 0.0010\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3464.3699 - val_loss: 4438.6465 - lr: 0.0010\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3463.5415 - val_loss: 4438.3579 - lr: 0.0010\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3463.5771 - val_loss: 4433.1255 - lr: 0.0010\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3460.3342 - val_loss: 4431.2661 - lr: 0.0010\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3459.0645 - val_loss: 4428.7524 - lr: 0.0010\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3458.3638 - val_loss: 4429.1548 - lr: 0.0010\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3456.5916 - val_loss: 4426.4673 - lr: 0.0010\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3454.6116 - val_loss: 4425.4741 - lr: 0.0010\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3453.5503 - val_loss: 4423.1353 - lr: 0.0010\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3451.9297 - val_loss: 4419.9668 - lr: 0.0010\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3450.8853 - val_loss: 4417.5991 - lr: 0.0010\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3449.9583 - val_loss: 4417.0645 - lr: 0.0010\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3449.6621 - val_loss: 4417.7280 - lr: 0.0010\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3447.8574 - val_loss: 4413.3872 - lr: 0.0010\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3445.8601 - val_loss: 4412.0586 - lr: 0.0010\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3445.8389 - val_loss: 4413.3027 - lr: 0.0010\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3442.8101 - val_loss: 4412.1406 - lr: 0.0010\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3441.1863 - val_loss: 4413.7266 - lr: 0.0010\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3440.0139 - val_loss: 4413.4639 - lr: 0.0010\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3438.8635 - val_loss: 4413.1548 - lr: 0.0010\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3437.4932 - val_loss: 4411.9624 - lr: 0.0010\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3435.7878 - val_loss: 4410.2544 - lr: 0.0010\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3434.9309 - val_loss: 4408.0337 - lr: 0.0010\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3433.9426 - val_loss: 4404.0220 - lr: 0.0010\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3433.0300 - val_loss: 4401.1660 - lr: 0.0010\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3431.0288 - val_loss: 4402.1455 - lr: 0.0010\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3429.5024 - val_loss: 4400.7192 - lr: 0.0010\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3429.2927 - val_loss: 4397.0298 - lr: 0.0010\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3427.4597 - val_loss: 4395.3179 - lr: 0.0010\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3426.1082 - val_loss: 4392.9424 - lr: 0.0010\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3426.1426 - val_loss: 4390.0820 - lr: 0.0010\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3423.9536 - val_loss: 4389.8599 - lr: 0.0010\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3421.7695 - val_loss: 4390.4570 - lr: 0.0010\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3420.4717 - val_loss: 4394.0942 - lr: 0.0010\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3418.4902 - val_loss: 4395.4351 - lr: 0.0010\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3417.4575 - val_loss: 4395.0884 - lr: 0.0010\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3417.0288 - val_loss: 4396.3560 - lr: 0.0010\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3415.6350 - val_loss: 4391.8301 - lr: 0.0010\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3414.0305 - val_loss: 4390.8042 - lr: 0.0010\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3412.6753 - val_loss: 4389.6685 - lr: 0.0010\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3411.1355 - val_loss: 4386.3457 - lr: 0.0010\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3409.9136 - val_loss: 4384.8232 - lr: 0.0010\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3408.7490 - val_loss: 4382.8281 - lr: 0.0010\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3407.0530 - val_loss: 4382.6436 - lr: 0.0010\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3406.1938 - val_loss: 4383.4126 - lr: 0.0010\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3406.0215 - val_loss: 4379.4321 - lr: 0.0010\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3403.1572 - val_loss: 4380.3643 - lr: 0.0010\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3401.9421 - val_loss: 4380.5620 - lr: 0.0010\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3401.0305 - val_loss: 4380.4849 - lr: 0.0010\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3399.7930 - val_loss: 4381.2485 - lr: 0.0010\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3398.5745 - val_loss: 4378.9580 - lr: 0.0010\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3397.1453 - val_loss: 4374.6274 - lr: 0.0010\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3397.3950 - val_loss: 4368.6187 - lr: 0.0010\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3395.0276 - val_loss: 4365.2979 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Learning rate scheduler\n",
    "def learning_rate(epoch, lr):\n",
    "    if epoch >= 50:\n",
    "        return 0.001\n",
    "    return 0.01\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(learning_rate)\n",
    "\n",
    "model.compile(\n",
    "    tf.keras.optimizers.SGD(0.01, 0.9),\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a63d415",
   "metadata": {},
   "source": [
    "## Show the weights and bias terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e3fcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer weights: [<tf.Variable 'dense/kernel:0' shape=(10, 1) dtype=float32, numpy=\n",
      "array([[  56.224697],\n",
      "       [   0.821621],\n",
      "       [ 206.38057 ],\n",
      "       [ 148.6324  ],\n",
      "       [  46.371983],\n",
      "       [  32.37847 ],\n",
      "       [-112.345406],\n",
      "       [ 111.29083 ],\n",
      "       [ 167.3441  ],\n",
      "       [ 110.312935]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([152.94556], dtype=float32)>]\n",
      "Layer bias: <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([152.94556], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# Print values of the weights\n",
    "for layer in model.layers:\n",
    "    print(f\"Layer weights: {layer.weights}\")\n",
    "    print(f\"Layer bias: {layer.bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958580e6",
   "metadata": {},
   "source": [
    "## Display both training- and validation loss per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b119fd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fad18596880>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss\n",
    "plt.plot(r.history['loss'], label='Training loss')\n",
    "plt.plot(r.history['val_loss'], label='Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc166737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 4365.2979\n",
      "Model evaluation: 4365.2978515625\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model evaluation: {model.evaluate(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c67213",
   "metadata": {},
   "source": [
    "## Pick a random feature vector from the test set and output both predicted and the true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df5b8598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 155.5009765625, true value: 170.0\n",
      "Predicted value: 127.75154113769531, true value: 60.0\n",
      "Predicted value: 211.2311248779297, true value: 277.0\n",
      "Predicted value: 204.67137145996094, true value: 180.0\n",
      "Predicted value: 162.71200561523438, true value: 310.0\n",
      "Predicted value: 100.87903594970703, true value: 45.0\n",
      "Predicted value: 122.03954315185547, true value: 39.0\n",
      "Predicted value: 131.3366241455078, true value: 79.0\n",
      "Predicted value: 164.39358520507812, true value: 221.0\n",
      "Predicted value: 187.35508728027344, true value: 150.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    index = np.random.choice(X_test.shape[0], 1)\n",
    "    print(f'Predicted value: {model.predict(X_test[index])[0][0]}, true value: {y_test[index[0]]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
