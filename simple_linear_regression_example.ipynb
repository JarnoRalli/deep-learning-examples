{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2d777e",
   "metadata": {},
   "source": [
    "# Simple Linear Regression Example\n",
    "\n",
    "This example uses the diabetes data from Sklearn in order to train a linear regression model. The data contains ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "Attribute information: \n",
    "- ***age*** age in years\n",
    "- ***sex*** sex of the person in question\n",
    "- ***bmi*** body mass index\n",
    "- ***bp*** average blood pressure\n",
    "- ***s1*** tc, total serum cholesterol\n",
    "- ***s2*** ldl, low-density lipoproteins\n",
    "- ***s3*** hdl, high-density lipoproteins\n",
    "- ***s4*** tch, total cholesterol / HDL\n",
    "- ***s5*** ltg, possibly log of serum triglycerides level\n",
    "- ***s6*** glu, blood sugar level\n",
    "\n",
    "The model (linear algebra) is `Ax = b`, where length of `x` is 10+1 due to the bias term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "210ec8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Reduce TF verbosity\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('INFO') # Reduce TF verbosity\n",
    "print(f\"tensorflow version: {tf.__version__}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979662d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data: <class 'sklearn.utils.Bunch'>\n",
      "Keys: dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])\n",
      "Feature names: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "Size of data.data: (442, 10)\n",
      "Size of data.target: (442,)\n"
     ]
    }
   ],
   "source": [
    "data = load_diabetes()\n",
    "\n",
    "print(f\"Type of data: {type(data)}\")\n",
    "print(f\"Keys: {data.keys()}\")\n",
    "print(f\"Feature names: {data.feature_names}\")\n",
    "print(f\"Size of data.data: {data.data.shape}\")\n",
    "print(f\"Size of data.target: {data.target.shape}\")\n",
    "N, D = data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b8c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "# Normalize X\n",
    "X -= X.mean()\n",
    "y = data.target\n",
    "\n",
    "# Sprint input features and target into train- and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0147f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(D,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ae8519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 1s 12ms/step - loss: 20763.7305 - val_loss: 7631.2124\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 7124.8657 - val_loss: 7131.0146\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 8082.7524 - val_loss: 5728.5815\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6128.6699 - val_loss: 5094.8740\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6210.7622 - val_loss: 5229.9570\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 6007.0537 - val_loss: 4910.6616\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5845.8330 - val_loss: 4840.8696\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5770.9121 - val_loss: 4779.5679\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5704.8477 - val_loss: 4731.2090\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5646.9014 - val_loss: 4658.7656\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5577.3882 - val_loss: 4604.9971\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5533.0327 - val_loss: 4552.3701\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5481.5195 - val_loss: 4539.0928\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5418.6001 - val_loss: 4472.1821\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 5343.8828 - val_loss: 4408.9185\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5302.3755 - val_loss: 4362.9487\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5251.4014 - val_loss: 4319.1533\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5193.2236 - val_loss: 4272.7979\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5134.5767 - val_loss: 4240.1475\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5091.8945 - val_loss: 4191.2056\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5040.3311 - val_loss: 4153.2920\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5002.6167 - val_loss: 4112.5571\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4962.8413 - val_loss: 4075.0898\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4925.5879 - val_loss: 4043.8643\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4870.4390 - val_loss: 4006.7908\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4840.4233 - val_loss: 3974.3540\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4806.8735 - val_loss: 3940.1250\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4759.7271 - val_loss: 3909.0530\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4726.9653 - val_loss: 3878.7642\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4694.7612 - val_loss: 3849.6960\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4652.3711 - val_loss: 3822.7603\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4620.6367 - val_loss: 3796.7510\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4591.7529 - val_loss: 3774.4062\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4555.2935 - val_loss: 3745.1733\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4524.3804 - val_loss: 3715.7312\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4494.6724 - val_loss: 3693.4714\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4490.6133 - val_loss: 3681.3767\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4433.3525 - val_loss: 3643.5437\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4455.9321 - val_loss: 3636.9734\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4423.3999 - val_loss: 3622.4153\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4375.9644 - val_loss: 3583.2395\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4328.8955 - val_loss: 3559.1914\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4302.4185 - val_loss: 3543.9678\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4277.1904 - val_loss: 3521.0278\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4256.5190 - val_loss: 3510.6863\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4232.0947 - val_loss: 3489.8960\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4210.8799 - val_loss: 3470.4058\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4200.0645 - val_loss: 3447.9146\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4189.6060 - val_loss: 3442.3291\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4149.0615 - val_loss: 3418.5134\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4124.0869 - val_loss: 3409.2500\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4115.5029 - val_loss: 3404.8242\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4109.9077 - val_loss: 3400.5818\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4107.8672 - val_loss: 3398.1799\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4105.1890 - val_loss: 3396.4180\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4103.1670 - val_loss: 3394.9963\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4102.1704 - val_loss: 3393.2861\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4099.2988 - val_loss: 3392.2051\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4098.0801 - val_loss: 3390.8655\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4095.5549 - val_loss: 3390.2883\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4095.2644 - val_loss: 3389.5635\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4096.0444 - val_loss: 3389.1006\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4093.1492 - val_loss: 3389.2954\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4090.5510 - val_loss: 3387.8613\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4089.1226 - val_loss: 3386.9316\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4086.9624 - val_loss: 3384.1641\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4084.9202 - val_loss: 3383.0449\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4081.4160 - val_loss: 3380.1416\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4081.0579 - val_loss: 3377.3496\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4077.9438 - val_loss: 3375.2751\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4076.4272 - val_loss: 3374.0713\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4073.9084 - val_loss: 3372.9421\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4072.1035 - val_loss: 3372.3274\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4070.5007 - val_loss: 3371.1665\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4068.8716 - val_loss: 3370.0029\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4067.1868 - val_loss: 3367.9761\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4066.0046 - val_loss: 3365.7454\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4063.8848 - val_loss: 3363.7791\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4062.2605 - val_loss: 3362.1760\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4062.0520 - val_loss: 3360.7180\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4058.4531 - val_loss: 3359.3950\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4057.6204 - val_loss: 3358.3115\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4054.5955 - val_loss: 3357.0579\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4052.6790 - val_loss: 3355.7654\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4050.8867 - val_loss: 3354.0706\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4049.2339 - val_loss: 3352.7275\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4046.6313 - val_loss: 3351.6904\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4044.3508 - val_loss: 3351.2144\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4044.6228 - val_loss: 3351.1675\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4042.4038 - val_loss: 3349.2986\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4040.8513 - val_loss: 3347.0720\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4038.7478 - val_loss: 3345.7686\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4037.9270 - val_loss: 3344.3982\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4035.4121 - val_loss: 3343.3481\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4033.4202 - val_loss: 3342.5469\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4035.0034 - val_loss: 3343.4590\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4031.7910 - val_loss: 3342.7490\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4031.4148 - val_loss: 3339.7969\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4029.5491 - val_loss: 3337.9243\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4025.8923 - val_loss: 3336.8044\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4023.9492 - val_loss: 3335.2751\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4025.3386 - val_loss: 3332.6455\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4021.0667 - val_loss: 3331.6675\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4018.2148 - val_loss: 3330.7510\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4019.8257 - val_loss: 3330.7642\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4017.6555 - val_loss: 3328.2349\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4013.4358 - val_loss: 3326.4092\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4012.1587 - val_loss: 3325.3188\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4010.1123 - val_loss: 3324.4387\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4008.5601 - val_loss: 3323.9397\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4007.8572 - val_loss: 3322.4810\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4005.6655 - val_loss: 3321.4004\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4005.4429 - val_loss: 3320.3213\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4003.3091 - val_loss: 3318.4871\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 4001.2217 - val_loss: 3317.5425\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 4000.8320 - val_loss: 3315.2742\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3998.8645 - val_loss: 3313.7046\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3996.0613 - val_loss: 3312.3967\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3995.0181 - val_loss: 3311.7529\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3993.2292 - val_loss: 3309.8794\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3990.5364 - val_loss: 3308.6836\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3989.1262 - val_loss: 3307.5361\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3988.2424 - val_loss: 3306.8394\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3986.5989 - val_loss: 3305.9993\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3983.8560 - val_loss: 3304.2292\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3982.7539 - val_loss: 3302.9692\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3980.6973 - val_loss: 3301.8730\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3979.3442 - val_loss: 3300.7778\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3978.8252 - val_loss: 3299.0701\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3976.3687 - val_loss: 3298.2356\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3974.9290 - val_loss: 3297.0063\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3973.2446 - val_loss: 3295.9553\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3972.6711 - val_loss: 3295.0815\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3971.6504 - val_loss: 3294.9604\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3968.9565 - val_loss: 3293.3459\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3967.4844 - val_loss: 3292.0669\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3966.4062 - val_loss: 3291.2891\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3964.4363 - val_loss: 3290.3459\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3962.6321 - val_loss: 3288.9263\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3960.3547 - val_loss: 3286.7598\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3961.7952 - val_loss: 3284.5715\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3957.6111 - val_loss: 3283.3914\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3958.1470 - val_loss: 3282.2056\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3955.1714 - val_loss: 3281.0688\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3953.3733 - val_loss: 3279.9395\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3952.1929 - val_loss: 3278.9104\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3950.6101 - val_loss: 3277.6482\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3948.8872 - val_loss: 3276.4980\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3947.0325 - val_loss: 3275.6995\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3947.4780 - val_loss: 3275.7554\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3945.5312 - val_loss: 3275.3916\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3944.8459 - val_loss: 3272.7581\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3941.0366 - val_loss: 3271.4175\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3940.0618 - val_loss: 3270.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3937.5417 - val_loss: 3269.4170\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3936.7268 - val_loss: 3268.9556\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3935.4526 - val_loss: 3268.1506\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3933.9827 - val_loss: 3268.4255\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3933.6389 - val_loss: 3268.1709\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3933.2229 - val_loss: 3267.0994\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3933.3147 - val_loss: 3263.9331\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3928.1833 - val_loss: 3262.7026\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3927.6917 - val_loss: 3260.9031\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3925.0383 - val_loss: 3259.5479\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3923.7336 - val_loss: 3258.3369\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3922.6638 - val_loss: 3257.0139\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3922.0288 - val_loss: 3256.7925\n",
      "Epoch 168/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3920.3945 - val_loss: 3256.6116\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3919.6765 - val_loss: 3255.7058\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3917.4883 - val_loss: 3254.2148\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3918.6545 - val_loss: 3251.6067\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3913.8877 - val_loss: 3250.7239\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3912.5181 - val_loss: 3249.7053\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3911.0076 - val_loss: 3248.7808\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3910.8647 - val_loss: 3247.7537\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3908.2788 - val_loss: 3246.7888\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3907.6406 - val_loss: 3245.9971\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3907.7056 - val_loss: 3244.5142\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3904.3420 - val_loss: 3243.4988\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3902.9954 - val_loss: 3242.6746\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3904.2292 - val_loss: 3241.2678\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3899.9290 - val_loss: 3240.2290\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3898.1099 - val_loss: 3239.2231\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3897.2915 - val_loss: 3238.7361\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3896.9851 - val_loss: 3238.0913\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3896.3525 - val_loss: 3236.1018\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3892.6174 - val_loss: 3235.2095\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3891.0793 - val_loss: 3234.0371\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3890.3931 - val_loss: 3232.9875\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3888.6055 - val_loss: 3232.0342\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3887.1157 - val_loss: 3230.9314\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3885.7505 - val_loss: 3230.2629\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3884.3079 - val_loss: 3229.4187\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3885.4109 - val_loss: 3228.6528\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3880.9773 - val_loss: 3227.2092\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3880.0574 - val_loss: 3225.7097\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3878.9561 - val_loss: 3224.7031\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3877.7466 - val_loss: 3223.7241\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3875.5688 - val_loss: 3222.8223\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 3873.6055 - val_loss: 3222.1924\n"
     ]
    }
   ],
   "source": [
    "# Learning rate scheduler\n",
    "def learning_rate(epoch, lr):\n",
    "    if epoch >= 50:\n",
    "        return 0.001\n",
    "    return 0.01\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(learning_rate)\n",
    "\n",
    "model.compile(\n",
    "    tf.keras.optimizers.SGD(0.01, 0.9),\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e3fcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer weights: [<tf.Variable 'dense/kernel:0' shape=(10, 1) dtype=float32, numpy=\n",
      "array([[  37.472744 ],\n",
      "       [  -4.351261 ],\n",
      "       [ 197.19902  ],\n",
      "       [ 154.9576   ],\n",
      "       [  19.129047 ],\n",
      "       [   6.7348456],\n",
      "       [-131.22763  ],\n",
      "       [ 120.71107  ],\n",
      "       [ 180.50064  ],\n",
      "       [ 127.55395  ]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([151.90167], dtype=float32)>]\n",
      "Layer bias: <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([151.90167], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# Print values of the weights\n",
    "for layer in model.layers:\n",
    "    print(f\"Layer weights: {layer.weights}\")\n",
    "    print(f\"Layer bias: {layer.bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b119fd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd69c4384c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss\n",
    "plt.plot(r.history['loss'], label='Training loss')\n",
    "plt.plot(r.history['val_loss'], label='Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc166737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 3222.1924\n",
      "Model evaluation: 3222.1923828125\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model evaluation: {model.evaluate(X_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
